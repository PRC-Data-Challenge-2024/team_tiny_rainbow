{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12342f03-8eb3-48e4-ac47-f4dc3d691932",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lightgbm Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23ff59ad-e6f3-4acf-bff2-3f9307ec3043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBRegressor, callback\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import json\n",
    "import joblib \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from lightgbm import LGBMRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33936ce9-6883-4634-9cdf-7e48db301656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset after the exploratory data analysis\n",
    "challenge_set_updated = pd.read_csv(\"./data/challenge_set_updated_v14.csv\")\n",
    "submission_set = pd.read_csv(\"./data/submission_set.csv\")\n",
    "submission_set_updated = pd.read_csv(\"./data/submission_set_updated_v14.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4836c392-b8fe-4f37-97f1-190b07bd1b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to drop columns with more than 40% missing values, except for 'tow' in the submission set\n",
    "def drop_columns_above_threshold(df, threshold=40, preserve_columns=None):\n",
    "    if preserve_columns is None:\n",
    "        presegrve_columns = []\n",
    "    \n",
    "    missing_percentage = df.isna().mean() * 100\n",
    "    cols_to_keep = missing_percentage[missing_percentage <= threshold].index.tolist()\n",
    "    \n",
    "    # Ensure columns in preserve_columns are kept even if they exceed the threshold\n",
    "    cols_to_keep.extend([col for col in preserve_columns if col in df.columns])\n",
    "    \n",
    "    df = df[cols_to_keep]\n",
    "    return df\n",
    "\n",
    "# Applying the function to challenge_set_updated\n",
    "challenge_set_updated = drop_columns_above_threshold(challenge_set_updated)\n",
    "\n",
    "# Applying the function to submission_set_updated, keeping 'tow'\n",
    "submission_set_updated = drop_columns_above_threshold(submission_set_updated, preserve_columns=['tow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eea44da-9253-4bd0-8240-be0f2c454a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_170565/653332527.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[numeric_columns] = df[numeric_columns].fillna(method='ffill').fillna(df.median())\n",
      "/tmp/ipykernel_170565/653332527.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[numeric_columns] = df[numeric_columns].fillna(method='ffill').fillna(df.median())\n"
     ]
    }
   ],
   "source": [
    "def clean_data_better(df, threshold=1e10):\n",
    "    # Replace inf and -inf with NaN using vectorized operations\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    # Mask values above the threshold with NaN directly using vectorized operations\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    df[numeric_columns] = df[numeric_columns].mask(df[numeric_columns].abs() > threshold)\n",
    "    \n",
    "    # Fill NaNs using a combined approach - first forward fill, then median\n",
    "    df[numeric_columns] = df[numeric_columns].fillna(method='ffill').fillna(df.median())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Applying the improved cleaning function\n",
    "challenge_set_updated = clean_data_better(challenge_set_updated)\n",
    "submission_set_updated = clean_data_better(submission_set_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f017078-f0cd-4e9f-9ae3-658d1b560116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary change this part to test the model before the training process\n",
    "df = challenge_set_updated.iloc[:,:]\n",
    "\n",
    "# Separating features and target variable\n",
    "X = df.drop('tow', axis=1)\n",
    "y = df['tow']\n",
    "\n",
    "n_jobs = os.cpu_count() // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19810434-b559-47aa-b836-1d6adb80443f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l2 is set=0.46415888336127775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.46415888336127775\n",
      "[LightGBM] [Warning] early_stopping_round is set=20, early_stopping_rounds=20 will be ignored. Current value: early_stopping_round=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.166810053720005, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.166810053720005\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.46415888336127775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.46415888336127775\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.166810053720005, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.166810053720005\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.749781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 17408\n",
      "[LightGBM] [Info] Number of data points in the train set: 236168, number of used features: 418\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.46415888336127775, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.46415888336127775\n",
      "[LightGBM] [Warning] early_stopping_round is set=20, early_stopping_rounds=20 will be ignored. Current value: early_stopping_round=20\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.166810053720005, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.166810053720005\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 79525.199947\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training data into training and validation sets for early stopping\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the best parameters for LightGBM\n",
    "best_params = {\n",
    "    'subsample': 1.0,\n",
    "    'lambda_l2': 0.46415888336127775,  # reg_lambda in LightGBM\n",
    "    'lambda_l1': 0.166810053720005,    # reg_alpha in LightGBM\n",
    "    'min_child_weight': 4,             # This corresponds to min_data_in_leaf in LightGBM\n",
    "    'max_depth': 13,\n",
    "    'learning_rate': 0.01,\n",
    "    'colsample_bytree': 0.6            # same as feature_fraction in LightGBM\n",
    "}\n",
    "\n",
    "# Initialize the LightGBM model with the best parameters\n",
    "best_model = LGBMRegressor(\n",
    "    **best_params,\n",
    "    objective='regression',\n",
    "    random_state=42,\n",
    "    n_estimators=10_000_000,  # Set a high value to allow early stopping to find the best n_estimators\n",
    "    n_jobs=n_jobs,\n",
    "    metric=\"rmse\",            # Use rmse as the evaluation metric\n",
    "    early_stopping_rounds=20  # Early stopping based on validation performance\n",
    ")\n",
    "\n",
    "# Train the model on the training data with early stopping using the validation set\n",
    "best_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)])\n",
    "\n",
    "# Update best_params with the best number of estimators found during early stopping\n",
    "best_params['n_estimators'] = best_model.best_iteration_  # No need to add 1, LightGBM handles this\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"Best Model Performance - R^2 Score: {r2:.4f}, RMSE: {rmse:.4f}\")\n",
    "print(f\"Updated best_params: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9cc69f-c81a-4e13-a47a-43ecfc901801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save R², RMSE, and hyperparameters\n",
    "results = {\n",
    "    'R2': float(r2),\n",
    "    'RMSE': float(rmse),\n",
    "    'Best Parameters': {key: (int(value) if isinstance(value, np.integer) else float(value)\n",
    "                              if isinstance(value, np.floating) else value)\n",
    "                        for key, value in best_params.items()}\n",
    "}\n",
    "\n",
    "# Set timezone to São Paulo (UTC-3)\n",
    "saopaulo_tz = pytz.timezone('America/Sao_Paulo')\n",
    "timestamp = datetime.now(saopaulo_tz).strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Define logs directory, and create them if they don't exist\n",
    "logs_dir = 'logs'\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "\n",
    "# Define file paths within the respective directories\n",
    "results_file = os.path.join(logs_dir, f'model_results_{timestamp}.txt')\n",
    "\n",
    "# Save the results to a TXT file\n",
    "with open(results_file, 'w') as file:\n",
    "    file.write(f\"R2: {results['R2']}\\n\")\n",
    "    file.write(f\"RMSE: {results['RMSE']}\\n\")\n",
    "    file.write(\"Best Parameters:\\n\")\n",
    "    for param, value in results['Best Parameters'].items():\n",
    "        file.write(f\"  {param}: {value}\\n\")\n",
    "\n",
    "print(f\"Results saved to {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa803af4-452f-4f19-97b0-e1a5e69bf4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display evaluation metrics\n",
    "print(f\"Final Model Performance - R^2 Score: {r2:.4f}, RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc4fe08-cc67-4d28-8787-554c7e05917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models directory, and create it if it doesn't exist\n",
    "models_dir = 'models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Train the final model using the full dataset (training+validation+test) with the optimal n_estimators\n",
    "final_model = LGBMRegressor(**best_params, objective='regression', random_state=42, n_jobs=n_jobs)\n",
    "\n",
    "# Train the model on the entire dataset\n",
    "final_model.fit(X, y, verbose=100)\n",
    "\n",
    "print(\"Final model trained successfully using all available data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4865b87-8fb4-4d17-b844-4813da8d2f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths within the respective directories\n",
    "model_file = os.path.join(models_dir, f'trained_model_{timestamp}.joblib')\n",
    "\n",
    "# Save the trained model to a file in the models folder\n",
    "joblib.dump(final_model, model_file)\n",
    "print(f\"Model saved to {model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58333841-9122-4ed9-b751-4dfbf077609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_set_updated.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a5ee28-9a58-4fe5-9493-89c605857c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the final model to predict the `tow` for the submission_set_updated\n",
    "submission_set_features = submission_set_updated.iloc[:,:-1]\n",
    "submission_set['tow'] = final_model.predict(submission_set_features)\n",
    "\n",
    "submission_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "598c600c-c2d2-46f2-a9da-e71acc696e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the submissions directory and create it if it doesn't exist\n",
    "submissions_dir = 'submissions'\n",
    "os.makedirs(submissions_dir, exist_ok=True)\n",
    "\n",
    "# Save the submission with a timestamp in the filename\n",
    "submission_file = os.path.join(submissions_dir, f\"submission_{timestamp}.csv\")\n",
    "submission_set.to_csv(submission_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
