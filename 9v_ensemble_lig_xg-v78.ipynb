{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12342f03-8eb3-48e4-ac47-f4dc3d691932",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lightgbm+XgBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23ff59ad-e6f3-4acf-bff2-3f9307ec3043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBRegressor, callback\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import json\n",
    "import joblib \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from lightgbm import LGBMRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33936ce9-6883-4634-9cdf-7e48db301656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset after the exploratory data analysis\n",
    "challenge_set_updated = pd.read_csv(\"./data/challenge_set_updated_v16.csv\")\n",
    "submission_set = pd.read_csv(\"./data/submission_set.csv\")\n",
    "submission_set_updated = pd.read_csv(\"./data/submission_set_updated_v16.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4836c392-b8fe-4f37-97f1-190b07bd1b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to drop columns with more than 40% missing values, except for 'tow' in the submission set\n",
    "def drop_columns_above_threshold(df, threshold=40, preserve_columns=None):\n",
    "    if preserve_columns is None:\n",
    "        preserve_columns = []\n",
    "    \n",
    "    missing_percentage = df.isna().mean() * 100\n",
    "    cols_to_keep = missing_percentage[missing_percentage <= threshold].index.tolist()\n",
    "    \n",
    "    # Ensure columns in preserve_columns are kept even if they exceed the threshold\n",
    "    cols_to_keep.extend([col for col in preserve_columns if col in df.columns])\n",
    "    \n",
    "    df = df[cols_to_keep]\n",
    "    return df\n",
    "\n",
    "# Applying the function to challenge_set_updated\n",
    "challenge_set_updated = drop_columns_above_threshold(challenge_set_updated)\n",
    "\n",
    "# Applying the function to submission_set_updated, keeping 'tow'\n",
    "submission_set_updated = drop_columns_above_threshold(submission_set_updated, preserve_columns=['tow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eea44da-9253-4bd0-8240-be0f2c454a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16333/653332527.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[numeric_columns] = df[numeric_columns].fillna(method='ffill').fillna(df.median())\n",
      "/tmp/ipykernel_16333/653332527.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[numeric_columns] = df[numeric_columns].fillna(method='ffill').fillna(df.median())\n"
     ]
    }
   ],
   "source": [
    "def clean_data_better(df, threshold=1e10):\n",
    "    # Replace inf and -inf with NaN using vectorized operations\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    # Mask values above the threshold with NaN directly using vectorized operations\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    df[numeric_columns] = df[numeric_columns].mask(df[numeric_columns].abs() > threshold)\n",
    "    \n",
    "    # Fill NaNs using a combined approach - first forward fill, then median\n",
    "    df[numeric_columns] = df[numeric_columns].fillna(method='ffill').fillna(df.median())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Applying the improved cleaning function\n",
    "challenge_set_updated = clean_data_better(challenge_set_updated)\n",
    "submission_set_updated = clean_data_better(submission_set_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f017078-f0cd-4e9f-9ae3-658d1b560116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary change this part to test the model before the training process\n",
    "df = challenge_set_updated.iloc[:,:]\n",
    "\n",
    "# Separating features and target variable\n",
    "X = df.drop('tow', axis=1)\n",
    "y = df['tow']\n",
    "\n",
    "n_jobs = os.cpu_count() // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19810434-b559-47aa-b836-1d6adb80443f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] early_stopping_round is set=20, early_stopping_rounds=20 will be ignored. Current value: early_stopping_round=20\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.200355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 36673\n",
      "[LightGBM] [Info] Number of data points in the train set: 236168, number of used features: 522\n",
      "[LightGBM] [Warning] early_stopping_round is set=20, early_stopping_rounds=20 will be ignored. Current value: early_stopping_round=20\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 79525.199947\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define parameters for LightGBM\n",
    "lgb_params = {\n",
    "    'subsample': 1.0,\n",
    "    'reg_lambda': 0.46415888336127775,  # L2 regularization\n",
    "    'reg_alpha': 0.166810053720005,     # L1 regularization\n",
    "    'min_child_weight': 4,\n",
    "    'max_depth': 13,\n",
    "    'learning_rate': 0.01,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'objective': 'regression',\n",
    "    'random_state': 42,\n",
    "    'n_estimators': 10000,              # Large number, with early stopping\n",
    "    'metric': 'rmse',\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Define parameters for XGBoost\n",
    "xgb_params = {\n",
    "    'subsample': 1.0,\n",
    "    'reg_lambda': 0.46415888336127775,  # L2 regularization\n",
    "    'reg_alpha': 0.166810053720005,     # L1 regularization\n",
    "    'min_child_weight': 4,\n",
    "    'max_depth': 13,\n",
    "    'learning_rate': 0.01,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'random_state': 42,\n",
    "    'n_estimators': 10000,              # Large number, with early stopping\n",
    "    'eval_metric': 'rmse',\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Initialize the models\n",
    "lgb_model = LGBMRegressor(**lgb_params, early_stopping_rounds=20)\n",
    "xgb_model = XGBRegressor(**xgb_params)\n",
    "\n",
    "# Train both models with early stopping\n",
    "lgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
    "xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=20, verbose=False)\n",
    "\n",
    "# Update parameters with the best number of estimators found\n",
    "lgb_params['n_estimators'] = lgb_model.best_iteration_\n",
    "xgb_params['n_estimators'] = xgb_model.best_iteration\n",
    "\n",
    "# Predict with both models\n",
    "lgb_y_pred = lgb_model.predict(X_test)\n",
    "xgb_y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Ensemble prediction by averaging\n",
    "ensemble_pred = (lgb_y_pred + xgb_y_pred) / 2\n",
    "\n",
    "# Evaluate ensemble model on the test set\n",
    "ensemble_r2 = r2_score(y_test, ensemble_pred)\n",
    "ensemble_rmse = np.sqrt(mean_squared_error(y_test, ensemble_pred))\n",
    "\n",
    "print(f\"Ensemble Model Performance - R^2 Score: {ensemble_r2:.4f}, RMSE: {ensemble_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9cc69f-c81a-4e13-a47a-43ecfc901801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "# Assuming you have already computed ensemble_r2 and ensemble_rmse\n",
    "\n",
    "# Save R², RMSE, and hyperparameters\n",
    "results = {\n",
    "    'R2': float(ensemble_r2),\n",
    "    'RMSE': float(ensemble_rmse),\n",
    "    'LightGBM Parameters': {key: (int(value) if isinstance(value, np.integer) else float(value)\n",
    "                                  if isinstance(value, np.floating) else value)\n",
    "                            for key, value in lgb_params.items()},\n",
    "    'XGBoost Parameters': {key: (int(value) if isinstance(value, np.integer) else float(value)\n",
    "                                  if isinstance(value, np.floating) else value)\n",
    "                           for key, value in xgb_params.items()}\n",
    "}\n",
    "\n",
    "# Set timezone to São Paulo (UTC-3)\n",
    "saopaulo_tz = pytz.timezone('America/Sao_Paulo')\n",
    "timestamp = datetime.now(saopaulo_tz).strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Define logs directory, and create them if they don't exist\n",
    "logs_dir = 'logs'\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "\n",
    "# Define file paths within the respective directories\n",
    "results_file = os.path.join(logs_dir, f'ensemble_model_results_{timestamp}.txt')\n",
    "\n",
    "# Save the results to a TXT file\n",
    "with open(results_file, 'w') as file:\n",
    "    file.write(f\"R2: {results['R2']}\\n\")\n",
    "    file.write(f\"RMSE: {results['RMSE']}\\n\")\n",
    "    file.write(\"LightGBM Parameters:\\n\")\n",
    "    for param, value in results['LightGBM Parameters'].items():\n",
    "        file.write(f\"  {param}: {value}\\n\")\n",
    "    file.write(\"XGBoost Parameters:\\n\")\n",
    "    for param, value in results['XGBoost Parameters'].items():\n",
    "        file.write(f\"  {param}: {value}\\n\")\n",
    "\n",
    "print(f\"Results saved to {results_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa803af4-452f-4f19-97b0-e1a5e69bf4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display evaluation metrics for the ensemble model\n",
    "print(f\"Ensemble Model Performance - R^2 Score: {ensemble_r2:.4f}, RMSE: {ensemble_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc4fe08-cc67-4d28-8787-554c7e05917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models directory and create them if they don't exist\n",
    "models_dir = 'models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Initialize LightGBM and XGBoost models with final best parameters\n",
    "lgb_final_model = LGBMRegressor(**lgb_params, objective='regression', random_state=42)\n",
    "xgb_final_model = XGBRegressor(**xgb_params, objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Train LightGBM model on the entire training + validation set data\n",
    "lgb_final_model.fit(X, y)\n",
    "\n",
    "# Train XGBoost model on the entire training + validation set data\n",
    "xgb_final_model.fit(X, y)\n",
    "\n",
    "print(\"Final models trained successfully using all available data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4865b87-8fb4-4d17-b844-4813da8d2f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# Set timezone to São Paulo (UTC-3)\n",
    "saopaulo_tz = pytz.timezone('America/Sao_Paulo')\n",
    "timestamp = datetime.now(saopaulo_tz).strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Define file paths within the respective directories for both models\n",
    "lgb_model_file = os.path.join(models_dir, f'lgb_trained_model_{timestamp}.joblib')\n",
    "xgb_model_file = os.path.join(models_dir, f'xgb_trained_model_{timestamp}.joblib')\n",
    "\n",
    "# Save the trained LightGBM model to a file in the models folder\n",
    "joblib.dump(lgb_final_model, lgb_model_file)\n",
    "print(f\"LightGBM Model saved to {lgb_model_file}\")\n",
    "\n",
    "# Save the trained XGBoost model to a file in the models folder\n",
    "joblib.dump(xgb_final_model, xgb_model_file)\n",
    "print(f\"XGBoost Model saved to {xgb_model_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58333841-9122-4ed9-b751-4dfbf077609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_set_updated.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a5ee28-9a58-4fe5-9493-89c605857c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'submission_set_updated' is your full dataset including features and target\n",
    "submission_set_features = submission_set_updated.iloc[:, :-1]  # Exclude the target column for prediction\n",
    "\n",
    "# Predict with both LightGBM and XGBoost models\n",
    "lgb_predictions = lgb_final_model.predict(submission_set_features)\n",
    "xgb_predictions = xgb_final_model.predict(submission_set_features)\n",
    "\n",
    "# Average the predictions from both models\n",
    "ensemble_predictions = (lgb_predictions + xgb_predictions) / 2\n",
    "\n",
    "# Add the ensemble predictions to the submission_set\n",
    "submission_set_updated['tow'] = ensemble_predictions\n",
    "\n",
    "submission_set_updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "598c600c-c2d2-46f2-a9da-e71acc696e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the submissions directory and create it if it doesn't exist\n",
    "submissions_dir = 'submissions'\n",
    "os.makedirs(submissions_dir, exist_ok=True)\n",
    "\n",
    "# Save the submission with a timestamp in the filename\n",
    "submission_file = os.path.join(submissions_dir, f\"submission_{timestamp}.csv\")\n",
    "submission_set.to_csv(submission_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af54ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
