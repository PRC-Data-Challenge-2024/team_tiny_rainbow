{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carolima/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import json\n",
    "import joblib \n",
    "import os\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset after the exploratory data analysis\n",
    "challenge_set_updated = pd.read_csv(\"./data/challenge_set_updated_v9_median.csv\")\n",
    "submission_set = pd.read_csv(\"./data/submission_set.csv\")\n",
    "submission_set_updated = pd.read_csv(\"./data/submission_set_updated_v9_median.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary change this part to test the model before the training process\n",
    "df = challenge_set_updated.iloc[:,:]\n",
    "# df = challenge_set_updated.sample(frac=0.001)\n",
    "\n",
    "# Separating features and target variable\n",
    "X = df.drop('tow', axis=1)\n",
    "y = df['tow']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Handle categorical columns by Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Specify the columns that are categorical\n",
    "categorical_cols = ['adep', 'ades', 'aircraft_type', 'wtc', 'airline', 'offblock_season', \n",
    "                    'flight_duration_category', 'adep_region', 'ades_region', 'flight_direction', \n",
    "                    'Manufacturer', 'Model_FAA', 'Physical_Class_Engine', 'FAA_Weight']\n",
    "\n",
    "# Convert these categorical columns into numerical form using Label Encoding\n",
    "for col in categorical_cols:\n",
    "    X[col] = label_encoder.fit_transform(X[col])\n",
    "\n",
    "# Now, you can proceed with training LightGBM with this processed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "import joblib  # or pickle\n",
    "\n",
    "# Load the saved models\n",
    "lgb_model = joblib.load('lgb_model.pkl')  # Adjust the file path as needed\n",
    "xgb_model = joblib.load('xgb_model.pkl')  # Adjust the file path as needed\n",
    "cat_model = joblib.load('cat_model.pkl')  # Adjust the file path as needed\n",
    "\n",
    "# Ensemble the pre-trained models\n",
    "ensemble_model = VotingRegressor(\n",
    "    estimators=[\n",
    "        ('lgb', lgb_model),\n",
    "        ('xgb', xgb_model),\n",
    "        ('cat', cat_model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Train the ensemble model on the entire dataset\n",
    "ensemble_model.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12511\n",
      "[LightGBM] [Info] Number of data points in the train set: 235756, number of used features: 80\n",
      "[LightGBM] [Info] Start training from score 79499.123553\n",
      "Best Model Performance - R^2 Score: 0.9964, RMSE: 3197.4635\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions\n",
    "y_pred = ensemble_model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(f\"Best Model Performance - R^2 Score: {r2:.4f}, RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ensemble_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the ensemble model to a file\n",
    "model_filename = 'ensemble_model.pkl'\n",
    "joblib.dump(ensemble_model, model_filename)\n",
    "\n",
    "print(f\"Model saved to {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        flight_id        date                          callsign  adep  \\\n",
      "0       248753821  2022-01-01  3b3de0f3ad0ee192513995c02f7bf7cf  LTFJ   \n",
      "1       248753822  2022-01-01  e06dd03d4a879ca37d9e18c1bd7cad16  EBBR   \n",
      "2       248754498  2022-01-01  2d3b1c962c78c4ebeef11bcd51b9e94c  KMIA   \n",
      "3       248757623  2022-01-01  81564432d3ee97c4bdf4cd8f006753dc  EGCN   \n",
      "4       248763603  2022-01-01  84be079d7e660db105d91f600b4b3d59  EIDW   \n",
      "...           ...         ...                               ...   ...   \n",
      "105786  258035188  2022-12-30  17d94ade55650fe95373f0b91ac01514  EPWA   \n",
      "105787  258035195  2022-12-30  c233a13ca55f946fdd1b13c444163764  LTFM   \n",
      "105788  258035230  2022-12-30  98bcbcc3e6db32d491c58262ab782f14  ESSA   \n",
      "105789  258035474  2022-12-30  71c9f60bd1c3f375bf365916d323f1a4  EGLL   \n",
      "105790  258035327  2022-12-30  2b62a10e5da30da7dadd1c930f1acd86  LSZH   \n",
      "\n",
      "                     name_adep country_code_adep  ades        name_ades  \\\n",
      "0       Istanbul Sabiha Gokcen                TR  LFLL             Lyon   \n",
      "1                     Brussels                BE  KJFK     New York JFK   \n",
      "2                        Miami                US  EGLL  London Heathrow   \n",
      "3          Doncaster Sheffield                GB  LEAL         Alicante   \n",
      "4                       Dublin                IE  LFLL             Lyon   \n",
      "...                        ...               ...   ...              ...   \n",
      "105786           Warsaw Chopin                PL  LOWW           Vienna   \n",
      "105787            iGA Istanbul                TR  EYVI          Vilnius   \n",
      "105788       Stockholm Arlanda                SE  LSZH           Zurich   \n",
      "105789         London Heathrow                GB  LSZH           Zurich   \n",
      "105790                  Zurich                CH  EGLC      London City   \n",
      "\n",
      "       country_code_ades  actual_offblock_time          arrival_time  \\\n",
      "0                     FR  2022-01-01T09:44:00Z  2022-01-01T12:48:33Z   \n",
      "1                     US  2022-01-01T09:45:00Z  2022-01-01T17:49:51Z   \n",
      "2                     GB  2022-01-01T01:52:00Z  2022-01-01T09:55:16Z   \n",
      "3                     ES  2022-01-01T08:20:00Z  2022-01-01T11:06:08Z   \n",
      "4                     FR  2022-01-01T11:01:00Z  2022-01-01T13:00:43Z   \n",
      "...                  ...                   ...                   ...   \n",
      "105786                AT  2022-12-30T06:03:00Z  2022-12-30T07:09:00Z   \n",
      "105787                LT  2022-12-30T05:52:00Z  2022-12-30T08:32:00Z   \n",
      "105788                CH  2022-12-30T05:59:14Z  2022-12-30T08:16:31Z   \n",
      "105789                CH  2022-12-30T06:00:00Z  2022-12-30T07:20:04Z   \n",
      "105790                GB  2022-12-30T06:04:00Z  2022-12-30T07:42:45Z   \n",
      "\n",
      "       aircraft_type wtc                           airline  flight_duration  \\\n",
      "0               B738   M  6351ec1b849adacc0cbb3b1313d8d39b              170   \n",
      "1               A333   H  bdeeef3a675587d530de70a25d7118d2              470   \n",
      "2               B77W   H  5543e4dc327359ffaf5b9c0e6faaf0e1              473   \n",
      "3               B38M   M  3922524069809ac4326134429751e26f              156   \n",
      "4               A320   M  a73f82288988b79be490c6322f4c32ed              105   \n",
      "...              ...  ..                               ...              ...   \n",
      "105786          E195   M  5d407cb11cc29578cc3e292e743f5393               57   \n",
      "105787          B39M   M  6351ec1b849adacc0cbb3b1313d8d39b              144   \n",
      "105788          A320   M  2d5def0a5a844b343ba1b7cc9cb28fa9              122   \n",
      "105789          A20N   M  2d5def0a5a844b343ba1b7cc9cb28fa9               66   \n",
      "105790          BCS1   M  2d5def0a5a844b343ba1b7cc9cb28fa9               88   \n",
      "\n",
      "        taxiout_time  flown_distance            tow  \n",
      "0                 15            1122   69437.627937  \n",
      "1                 15            3205  210264.988187  \n",
      "2                 10            3965  239229.689062  \n",
      "3                 10             986   56957.191350  \n",
      "4                 15             686   63703.609618  \n",
      "...              ...             ...            ...  \n",
      "105786             9             321   69411.026458  \n",
      "105787            16            1008  178191.342372  \n",
      "105788            15             819   72119.001192  \n",
      "105789            14             461   59261.797379  \n",
      "105790            11             457   64697.977890  \n",
      "\n",
      "[105791 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "submission_set_features = submission_set_updated.iloc[:,:-1]\n",
    "\n",
    "\n",
    "# Now you can use the model to make predictions\n",
    "submission_set['tow'] = ensemble_model.predict(submission_set_features)\n",
    "print(submission_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to submissions/submission_20241007_180401.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the submissions directory and create it if it doesn't exist\n",
    "submissions_dir = 'submissions'\n",
    "os.makedirs(submissions_dir, exist_ok=True)\n",
    "\n",
    "# Define a timestamp for the file name\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save the submission with a timestamp in the filename\n",
    "submission_file = os.path.join(submissions_dir, f\"submission_{timestamp}.csv\")\n",
    "\n",
    "# Assuming submission_set is a DataFrame, save it to CSV\n",
    "submission_set.to_csv(submission_file, index=False)\n",
    "\n",
    "print(f\"Submission saved to {submission_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
