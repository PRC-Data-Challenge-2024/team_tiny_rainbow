{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carolima/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "from lightgbm.callback import early_stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset after the exploratory data analysis\n",
    "challenge_set_updated = pd.read_csv(\"./data/challenge_set_updated_v13.csv\")\n",
    "submission_set = pd.read_csv(\"./data/submission_set.csv\")\n",
    "submission_set_updated = pd.read_csv(\"./data/submission_set_updated_v13.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating features and target variable\n",
    "X = challenge_set_updated.drop('tow', axis=1)\n",
    "y = challenge_set_updated['tow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "categorical_columns = ['adep', 'ades', 'aircraft_type', 'wtc', 'airline', 'offblock_season',\n",
    "                       'flight_duration_category', 'adep_region', 'ades_region',\n",
    "                       'flight_direction', 'Manufacturer', 'Model_FAA',\n",
    "                       'Physical_Class_Engine', 'FAA_Weight']\n",
    "\n",
    "# Encoding using LabelEncoder\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))  # Ensure data is string type before encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 2692.03\n"
     ]
    }
   ],
   "source": [
    "# Convert DataFrame to LightGBM Dataset, specifying categorical feature\n",
    "train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_columns, free_raw_data=False)\n",
    "valid_data = lgb.Dataset(X_val, label=y_val, categorical_feature=categorical_columns, free_raw_data=False)\n",
    "\n",
    "# Parameters\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'verbose': -1,\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'min_data_per_group': 100,  # Use this to prevent overfitting on categorical data\n",
    "    'cat_smooth': 10  # Smoothing factor to balance categorical feature influence\n",
    "}\n",
    "\n",
    "# Training the model\n",
    "# Training the model with early stopping\n",
    "bst = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=1000,\n",
    "    valid_sets=[valid_data],\n",
    "    callbacks=[early_stopping(stopping_rounds=50)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE of the validation set is: 2692.0330361958218\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for the validation set\n",
    "val_pred = bst.predict(X_val)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "\n",
    "# Print the RMSE\n",
    "print(f\"The RMSE of the validation set is: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        flight_id        date                          callsign  adep  \\\n",
      "0       248753821  2022-01-01  3b3de0f3ad0ee192513995c02f7bf7cf  LTFJ   \n",
      "1       248753822  2022-01-01  e06dd03d4a879ca37d9e18c1bd7cad16  EBBR   \n",
      "2       248754498  2022-01-01  2d3b1c962c78c4ebeef11bcd51b9e94c  KMIA   \n",
      "3       248757623  2022-01-01  81564432d3ee97c4bdf4cd8f006753dc  EGCN   \n",
      "4       248763603  2022-01-01  84be079d7e660db105d91f600b4b3d59  EIDW   \n",
      "...           ...         ...                               ...   ...   \n",
      "105954  258066302  2022-12-31  2d3b4446c4d05a25196a9d52cab936fb  LTFJ   \n",
      "105955  258068609  2022-12-31  253fd692ed441fac523081471c067772  LOWW   \n",
      "105956  258068876  2022-12-31  c9fca302ca2e28acab0eb0bb1b46f11b  LTFM   \n",
      "105957  258064675  2022-12-31  00f96ad0e382476649574ba044c764fc  EHAM   \n",
      "105958  258058370  2022-12-31  5f0c222c7f7ceff3fbe75c854cce74c9  UBBB   \n",
      "\n",
      "                     name_adep country_code_adep  ades          name_ades  \\\n",
      "0       Istanbul Sabiha Gokcen                TR  LFLL               Lyon   \n",
      "1                     Brussels                BE  KJFK       New York JFK   \n",
      "2                        Miami                US  EGLL    London Heathrow   \n",
      "3          Doncaster Sheffield                GB  LEAL           Alicante   \n",
      "4                       Dublin                IE  LFLL               Lyon   \n",
      "...                        ...               ...   ...                ...   \n",
      "105954  Istanbul Sabiha Gokcen                TR  EKCH         Copenhagen   \n",
      "105955                  Vienna                AT  KIAD  Washington Dulles   \n",
      "105956            iGA Istanbul                TR  LSZH             Zurich   \n",
      "105957               Amsterdam                NL  EDDF          Frankfurt   \n",
      "105958                    Baku                AZ  LTFM       iGA Istanbul   \n",
      "\n",
      "       country_code_ades  actual_offblock_time          arrival_time  \\\n",
      "0                     FR  2022-01-01T09:44:00Z  2022-01-01T12:48:33Z   \n",
      "1                     US  2022-01-01T09:45:00Z  2022-01-01T17:49:51Z   \n",
      "2                     GB  2022-01-01T01:52:00Z  2022-01-01T09:55:16Z   \n",
      "3                     ES  2022-01-01T08:20:00Z  2022-01-01T11:06:08Z   \n",
      "4                     FR  2022-01-01T11:01:00Z  2022-01-01T13:00:43Z   \n",
      "...                  ...                   ...                   ...   \n",
      "105954                DK  2022-12-31T09:36:00Z  2022-12-31T13:12:17Z   \n",
      "105955                US  2022-12-31T09:49:00Z  2022-12-31T19:38:26Z   \n",
      "105956                CH  2022-12-31T09:25:00Z  2022-12-31T12:24:24Z   \n",
      "105957                DE  2022-12-31T10:04:21Z  2022-12-31T10:55:35Z   \n",
      "105958                TR  2022-12-31T09:40:00Z  2022-12-31T12:28:00Z   \n",
      "\n",
      "       aircraft_type wtc                           airline  flight_duration  \\\n",
      "0               B738   M  6351ec1b849adacc0cbb3b1313d8d39b              170   \n",
      "1               A333   H  bdeeef3a675587d530de70a25d7118d2              470   \n",
      "2               B77W   H  5543e4dc327359ffaf5b9c0e6faaf0e1              473   \n",
      "3               B38M   M  3922524069809ac4326134429751e26f              156   \n",
      "4               A320   M  a73f82288988b79be490c6322f4c32ed              105   \n",
      "...              ...  ..                               ...              ...   \n",
      "105954          B38M   M  6351ec1b849adacc0cbb3b1313d8d39b              201   \n",
      "105955          B763   H  5d407cb11cc29578cc3e292e743f5393              575   \n",
      "105956          A321   M  6351ec1b849adacc0cbb3b1313d8d39b              154   \n",
      "105957          A320   M  f502877cab405652cf0dd70c2213e730               42   \n",
      "105958          B738   M  6351ec1b849adacc0cbb3b1313d8d39b              158   \n",
      "\n",
      "        taxiout_time  flown_distance            tow  \n",
      "0                 15            1122   68753.137199  \n",
      "1                 15            3205  209078.565177  \n",
      "2                 10            3965  204659.619562  \n",
      "3                 10             986   55947.612131  \n",
      "4                 15             686   64727.601943  \n",
      "...              ...             ...            ...  \n",
      "105954            15            1199   63897.686321  \n",
      "105955            14            3937  149633.948146  \n",
      "105956            25             988   73877.773804  \n",
      "105957             9             240   58466.830357  \n",
      "105958            10            1014   65274.862835  \n",
      "\n",
      "[105959 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# List of columns to encode\n",
    "categorical_columns = ['adep', 'ades', 'aircraft_type', 'wtc', 'airline', 'offblock_season', 'flight_duration_category', \n",
    "                       'adep_region', 'ades_region', 'flight_direction', 'Manufacturer', 'Model_FAA', \n",
    "                       'Physical_Class_Engine', 'FAA_Weight']\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoders = {}\n",
    "\n",
    "\n",
    "# Apply Label Encoding to each categorical column\n",
    "for column in categorical_columns:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    submission_set_updated[column] = label_encoders[column].fit_transform(submission_set_updated[column])\n",
    "\n",
    "\n",
    "# Now you should be able to run LightGBM predictions\n",
    "submission_set_features = submission_set_updated.iloc[:, :-1]\n",
    "submission_set['tow'] = bst.predict(submission_set_features)\n",
    "\n",
    "print(submission_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to submissions/submission_20241015_205815.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the submissions directory and create it if it doesn't exist\n",
    "submissions_dir = 'submissions'\n",
    "os.makedirs(submissions_dir, exist_ok=True)\n",
    "\n",
    "# Define a timestamp for the file name\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save the submission with a timestamp in the filename\n",
    "submission_file = os.path.join(submissions_dir, f\"submission_{timestamp}.csv\")\n",
    "\n",
    "# Assuming submission_set is a DataFrame, save it to CSV\n",
    "submission_set.to_csv(submission_file, index=False)\n",
    "\n",
    "print(f\"Submission saved to {submission_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
